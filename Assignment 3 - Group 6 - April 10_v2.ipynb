{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11921,"status":"ok","timestamp":1711632499767,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"644ZwyddeHZY"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.distributions import Categorical\n","\n","import gym\n","from tqdm import tqdm_notebook\n","import numpy as np\n","from collections import deque"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1711632499767,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"WTTkcXV3eHZa","outputId":"8f29d0d6-785e-4061-e041-d2dc17edde6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["#discount factor for future utilities\n","DISCOUNT_FACTOR = 0.99\n","\n","#number of episodes to run\n","NUM_EPISODES = 10\n","\n","#max steps per episode\n","MAX_STEPS = 5000\n","\n","#score agent needs for environment to be solved\n","SOLVED_SCORE = -13\n","\n","#device to run model on\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {DEVICE}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711632499767,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"ff3l9L7MeHZa"},"outputs":[],"source":["#Using a neural network to learn our policy parameters\n","class PolicyNetwork(nn.Module):\n","\n","    #Takes in observations and outputs actions\n","    def __init__(self, observation_space, action_space):\n","        super(PolicyNetwork, self).__init__()\n","        self.input_layer = nn.Linear(observation_space, 128)\n","        self.output_layer = nn.Linear(128, action_space)\n","\n","    #forward pass\n","    def forward(self, x):\n","        #input states\n","        x = self.input_layer(x)\n","\n","        #relu activation\n","        x = F.relu(x)\n","\n","        #actions\n","        actions = self.output_layer(x)\n","\n","        #get softmax for a probability distribution\n","        action_probs = F.softmax(actions, dim=1)\n","\n","        return action_probs"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1711632499768,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"n2-QB_v9eHZb"},"outputs":[],"source":["#Using a neural network to learn state value\n","class StateValueNetwork(nn.Module):\n","\n","    #Takes in state\n","    def __init__(self, observation_space):\n","        super(StateValueNetwork, self).__init__()\n","\n","        self.input_layer = nn.Linear(observation_space, 128)\n","        self.output_layer = nn.Linear(128, 1)\n","\n","    def forward(self, x):\n","        #input layer\n","        x = self.input_layer(x)\n","\n","        #activiation relu\n","        x = F.relu(x)\n","\n","        #get state value\n","        state_value = self.output_layer(x)\n","\n","        return state_value"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711632499768,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"-oanuRIdeHZb"},"outputs":[],"source":["def select_action(network, state):\n","    ''' Selects an action given current state\n","    Args:\n","    - network (Torch NN): network to process state\n","    - state (Array): Array of action space in an environment\n","\n","    Return:\n","    - (int): action that is selected\n","    - (float): log probability of selecting that action given state and network\n","    '''\n","\n","    #convert state to float tensor, add 1 dimension, allocate tensor on device\n","    # print(type(state[0]))\n","    # print(state[0])\n","    #OLD\n","    #state = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n","    #NEW\n","    #state = torch.tensor([state], dtype=torch.float).unsqueeze(0).to(DEVICE)\n","    # NEW NEW\n","    #state = torch.nn.functional.one_hot(torch.tensor(state), env.observation_space.n).float().to(DEVICE)\n","\n","    #use network to predict action probabilities\n","    action_probs = network(state)\n","    state = state.detach()  \n","    \n","    \n","    #sample an action using the probability distribution\n","    m = Categorical(action_probs)\n","    action = m.sample()\n","\n","    #return action\n","    return action.item(), m.log_prob(action)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5009,"status":"ok","timestamp":1711632504774,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"Gnk1vxtqeHZc","outputId":"54fbbc63-9650-4818-ce68-239274c2b449"},"outputs":[],"source":["#Make environment\n","env = gym.make('CliffWalking-v0')#, render_mode='human')\n","\n","#OLD Init network\n","#policy_network = PolicyNetwork(np.array(env.observation_space.n, env.action_space.n).to(DEVICE)\n","#stateval_network = StateValueNetwork(np.array(env.observation_space.n)).to(DEVICE)\n","#NEW Init network using observation space  value of 1.  The observation space is a single value representing the current state from 0-47\n","policy_network = PolicyNetwork(env.observation_space.n, env.action_space.n).to(DEVICE)\n","stateval_network = StateValueNetwork(env.observation_space.n).to(DEVICE)\n","\n","#Init optimizer\n","policy_optimizer = optim.SGD(policy_network.parameters(), lr=0.01)\n","stateval_optimizer = optim.SGD(stateval_network.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":194,"referenced_widgets":["525c0dbd25cd4722a5c667b29abbeb53","ff1dd190d2d341f98df729f2469897f6","99b7b748530a43749cec92d796a888d6","e1452f0677584b658ae316ea80d48fe2","cf408432e34541de83125d13dc3a2444","6d235bbceeb8484da4eb6e1e29696f70","e745e96fabdd4ec4b57681345002805f","d94dca28ee8543bc8995294fa5b50ca2","09cf1118e73f41e28dccff81fc9d6920","f54d93f7b77c4e5393ef0795977de8fa","db874a1e05ad4616af7cb7fa6b600a4b"]},"executionInfo":{"elapsed":134263,"status":"ok","timestamp":1711632639028,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"9h6lvmQQeHZc","outputId":"700e5517-6137-4673-9f05-46c809d90a53","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_10976\\1436982950.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for episode in tqdm_notebook(range(NUM_EPISODES)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ede67350dde46908bc815b5ca51539c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"IndexError","evalue":"Dimension out of range (expected to be in range of [-1, 0], but got 1)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(torch\u001b[38;5;241m.\u001b[39mtensor(state), env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mn)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#get action and log probability\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m action, lp \u001b[38;5;241m=\u001b[39m \u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#step with action\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# print(env.step(action))\u001b[39;00m\n\u001b[0;32m     26\u001b[0m new_state, reward, done, t, tt \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n","Cell \u001b[1;32mIn[5], line 23\u001b[0m, in \u001b[0;36mselect_action\u001b[1;34m(network, state)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m''' Selects an action given current state\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m- network (Torch NN): network to process state\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m- (float): log probability of selecting that action given state and network\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#convert state to float tensor, add 1 dimension, allocate tensor on device\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(type(state[0]))\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# print(state[0])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#use network to predict action probabilities\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m action_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mdetach()  \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#sample an action using the probability distribution\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mPolicyNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#get softmax for a probability distribution\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m action_probs \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action_probs\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1856\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1860\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n","\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"]}],"source":["#track scores\n","scores = []\n","\n","#track recent scores\n","recent_scores = deque(maxlen = 100)\n","\n","#run episodes\n","for episode in tqdm_notebook(range(NUM_EPISODES)):\n","\n","    #init variables\n","    state, _ = env.reset()\n","    #print(state)\n","    done = False\n","    score = 0\n","    I = 1\n","\n","    #run episode, update online\n","    for step in range(MAX_STEPS):\n","        state = torch.nn.functional.one_hot(torch.tensor(state), env.observation_space.n).float().to(DEVICE)\n","\n","        #get action and log probability\n","        action, lp = select_action(policy_network, state)\n","\n","        #step with action\n","        # print(env.step(action))\n","        new_state, reward, done, t, tt = env.step(action)\n","\n","        #NEW - added because cliffwalking env does not return done as True when agent falls off cliff\n","        #if reward == -100:\n","        #    done = True\n","        \n","        #NEW - check if agent has reached the end of the grid\n","        if new_state == 47:\n","            done = True\n","\n","        #update episode scor\n","        score += reward\n","\n","        #print(f\"episode: {episode}, Step: {step}, State: {state}, Action: {action}, Reward: {reward}, New State: {new_state}, Done: {done}, Score: {score}, t: {t}, tt: {tt}\")\n","\n","        reward_tensor = torch.tensor([reward]).float().unsqueeze(0).to(DEVICE)\n","\n","        #get state value of current state\n","        #OLD\n","        #state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(DEVICE)\n","        #NEW\n","        state_tensor = torch.nn.functional.one_hot(torch.tensor(state), env.observation_space.n).float().to(DEVICE)\n","        state_val = stateval_network(state_tensor)\n","\n","        #get state value of next state\n","        #OLD\n","        #new_state_tensor = torch.from_numpy(new_state).float().unsqueeze(0).to(DEVICE)\n","        #NEW\n","        new_state_tensor = torch.nn.functional.one_hot(torch.tensor(new_state), env.observation_space.n).float().to(DEVICE)\n","        new_state_val = stateval_network(new_state_tensor)\n","\n","        #if terminal state, next state val is 0\n","        if done:\n","            new_state_val = torch.tensor([0]).float().unsqueeze(0).to(DEVICE)\n","\n","        #calculate value function loss with MSE\n","        td_target = reward_tensor + DISCOUNT_FACTOR * new_state_val.item()\n","        val_loss = F.mse_loss(state_val, td_target.detach())\n","        #val_loss *= I\n","\n","        #calculate policy loss\n","        advantage = td_target - state_val\n","        policy_loss = -lp * advantage.detach()\n","        #policy_loss *= I\n","\n","        #Backpropagate policy\n","        policy_optimizer.zero_grad()\n","        policy_loss.backward(retain_graph=True)\n","        policy_optimizer.step()\n","\n","        #Backpropagate value\n","        stateval_optimizer.zero_grad()\n","        val_loss.backward()\n","        stateval_optimizer.step()\n","\n","        if done:\n","            print(f\"Episode {episode} finished after {step} steps at state {new_state} with score {score}\")\n","            break\n","\n","        #move into new state, discount I\n","        state = new_state\n","        I *= DISCOUNT_FACTOR\n","\n","    #append episode score\n","    scores.append(score)\n","    recent_scores.append(score)\n","\n","    #early stopping if we meet solved score goal\n","    if np.array(recent_scores).mean() >= SOLVED_SCORE:\n","        break\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"executionInfo":{"elapsed":2515,"status":"ok","timestamp":1711632641539,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"eN_dsh34eHZd","outputId":"d5bf7825-b000-428a-def9-0821ad99242d"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression\n","import seaborn as sns\n","import numpy as np\n","\n","sns.set()\n","\n","plt.plot(scores)\n","plt.ylabel('score')\n","plt.xlabel('episodes')\n","plt.title('Training score of Cliff Walking Actor-Critic TD(0)')\n","\n","reg = LinearRegression().fit(np.arange(len(scores)).reshape(-1, 1), np.array(scores).reshape(-1, 1))\n","y_pred = reg.predict(np.arange(len(scores)).reshape(-1, 1))\n","plt.plot(y_pred)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["a0fac43525074112bdacb6d11667f3bc","42f3b27605aa48d6bf1004ef461fcd4a","bc08e52e15f84170a22f24bd0f7c6e1f","2fc5b750906f4275b2a80f13fa7325ec","1dea3e8ce9a34d3891e687913a764be0","d7fc85521974471a98faa489d8854a0c","99c82031dc70470797cff78b4c774f45","f7361bc193824e3fb89ec348d6f1a47d","8de1ff42d9024f8fba7f546feaad1e79","156beeda0e8244a08d705b5ad0b6d7b9","66610f415a5641b99f9449e4a3ed7e93"]},"executionInfo":{"elapsed":2753,"status":"ok","timestamp":1711632644286,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"YBsTyflSeHZd","outputId":"2dc7be3c-8fa4-4367-ca2b-d5dc6e2f95d3"},"outputs":[],"source":["# done = False\n","# state, _ = env.reset()\n","# scores = []\n","\n","# for _ in tqdm_notebook(range(5)):\n","#     state, _ = env.reset()\n","#     # print(state)\n","#     done = False\n","#     score = 0\n","#     while not done:\n","#         env.render()\n","#         action, lp = select_action(policy_network, state)\n","#         new_state, reward, done, info, _ = env.step(action)\n","        \n","#         #NEW - added because cliffwalking env does not return done as True when agent falls off cliff\n","#         if reward == -100:\n","#             done = True\n","        \n","#         #NEW - check if agent has reached the end of the grid\n","#         if new_state == 47:\n","#             done = True\n","\n","#         score += reward\n","#         state = new_state\n","#     scores.append(score)\n","# env.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1711632644286,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"Z44ezbWweHZe"},"outputs":[],"source":["env.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1711632644286,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"mblaUqaAeHZf","outputId":"0e706ff0-8d59-4d8e-d192-770cc10d5a8a"},"outputs":[],"source":["np.array(scores).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1711632644286,"user":{"displayName":"Brian Ritchie","userId":"11272907696597641245"},"user_tz":240},"id":"Eci8IXI39qab"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1qt9kOndq-km-yiYpORtS17qhAPz7j6IO","timestamp":1711633056265}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09cf1118e73f41e28dccff81fc9d6920":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"156beeda0e8244a08d705b5ad0b6d7b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dea3e8ce9a34d3891e687913a764be0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fc5b750906f4275b2a80f13fa7325ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_156beeda0e8244a08d705b5ad0b6d7b9","placeholder":"​","style":"IPY_MODEL_66610f415a5641b99f9449e4a3ed7e93","value":" 50/50 [00:02&lt;00:00, 14.58it/s]"}},"42f3b27605aa48d6bf1004ef461fcd4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7fc85521974471a98faa489d8854a0c","placeholder":"​","style":"IPY_MODEL_99c82031dc70470797cff78b4c774f45","value":"100%"}},"525c0dbd25cd4722a5c667b29abbeb53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff1dd190d2d341f98df729f2469897f6","IPY_MODEL_99b7b748530a43749cec92d796a888d6","IPY_MODEL_e1452f0677584b658ae316ea80d48fe2"],"layout":"IPY_MODEL_cf408432e34541de83125d13dc3a2444"}},"66610f415a5641b99f9449e4a3ed7e93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d235bbceeb8484da4eb6e1e29696f70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8de1ff42d9024f8fba7f546feaad1e79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99b7b748530a43749cec92d796a888d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d94dca28ee8543bc8995294fa5b50ca2","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09cf1118e73f41e28dccff81fc9d6920","value":1000}},"99c82031dc70470797cff78b4c774f45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0fac43525074112bdacb6d11667f3bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42f3b27605aa48d6bf1004ef461fcd4a","IPY_MODEL_bc08e52e15f84170a22f24bd0f7c6e1f","IPY_MODEL_2fc5b750906f4275b2a80f13fa7325ec"],"layout":"IPY_MODEL_1dea3e8ce9a34d3891e687913a764be0"}},"bc08e52e15f84170a22f24bd0f7c6e1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7361bc193824e3fb89ec348d6f1a47d","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8de1ff42d9024f8fba7f546feaad1e79","value":50}},"cf408432e34541de83125d13dc3a2444":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7fc85521974471a98faa489d8854a0c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d94dca28ee8543bc8995294fa5b50ca2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db874a1e05ad4616af7cb7fa6b600a4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1452f0677584b658ae316ea80d48fe2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f54d93f7b77c4e5393ef0795977de8fa","placeholder":"​","style":"IPY_MODEL_db874a1e05ad4616af7cb7fa6b600a4b","value":" 1000/1000 [02:14&lt;00:00,  6.47it/s]"}},"e745e96fabdd4ec4b57681345002805f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f54d93f7b77c4e5393ef0795977de8fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7361bc193824e3fb89ec348d6f1a47d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff1dd190d2d341f98df729f2469897f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d235bbceeb8484da4eb6e1e29696f70","placeholder":"​","style":"IPY_MODEL_e745e96fabdd4ec4b57681345002805f","value":"100%"}}}}},"nbformat":4,"nbformat_minor":0}
